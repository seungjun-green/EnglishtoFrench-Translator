{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Cl22jormhntv",
        "IzEZKhTjhsoW",
        "3TJGpb6q_Cxl",
        "O7B_Bt54wt7u",
        "OhSvybqgwxlC",
        "nHfhOlKCtS_M",
        "N38wBTD-tXUU",
        "F4vX418ktZ4p"
      ],
      "toc_visible": true,
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages and Import Libraries"
      ],
      "metadata": {
        "id": "Cl22jormhntv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade tensorflow"
      ],
      "metadata": {
        "id": "nepaJbxQlvhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb3fbbb-3bb1-48e8-e45f-30cd584d74d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check tensorflow version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvHCpypflz0s",
        "outputId": "6aaee80c-9d44-4242-c658-5a0ac2ba63e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pevWExhahj9n"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import random\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downlaod Data and preprocess it"
      ],
      "metadata": {
        "id": "IzEZKhTjhsoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download [English-French Translation Dataset](https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset) from Kaggle"
      ],
      "metadata": {
        "id": "YRKc94CYiaU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')"
      ],
      "metadata": {
        "id": "lzeNMfWNhuad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dhruvildave/en-fr-translation-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKMZem7CiD-l",
        "outputId": "49f93ffb-2e76-4b9e-e787-a95d5f9c9061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading en-fr-translation-dataset.zip to /content\n",
            "100% 2.54G/2.54G [02:32<00:00, 17.7MB/s]\n",
            "100% 2.54G/2.54G [02:32<00:00, 17.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/en-fr-translation-dataset.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF5qynjXiJ5j",
        "outputId": "dd5bec8d-7fdc-4705-87b5-ac208b5f7a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/en-fr-translation-dataset.zip\n",
            "  inflating: en-fr.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look into the `train.csv` file"
      ],
      "metadata": {
        "id": "j6mVsC2pilLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Rest of Code"
      ],
      "metadata": {
        "id": "yoHKa3JzstPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_LAYERS = 4\n",
        "D_MODEL = 256\n",
        "DFF = 256\n",
        "NUM_HEADS = 4\n",
        "DROPOUT_RATE = 0.5\n",
        "TRAINING_EXMAPLES = 1800000\n",
        "WARMUP_STEPS = 35000"
      ],
      "metadata": {
        "id": "06q28HbQswds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/en-fr.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "I6PtUzoVigjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(n=TRAINING_EXMAPLES, random_state=42)"
      ],
      "metadata": {
        "id": "3BKSYqvpEzIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jdozX7SMROTp",
        "outputId": "1b72623b-1c02-408b-ba17-001a908d5f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                         en  \\\n",
              "17765420  Operating in the rugged Arctic always poses un...   \n",
              "7566010                        Building a Knowledge Culture   \n",
              "13382656  More than 360 current and former Cadets of the...   \n",
              "19904187  Like the Château Saint-Louis it was a 2-storey...   \n",
              "12978711  • L'administration québécoise trailed the Queb...   \n",
              "\n",
              "                                                         fr  \n",
              "17765420  Les conditions rudes de l’Arctique ont toujour...  \n",
              "7566010                    Création d'une culture du savoir  \n",
              "13382656  Plus de 360 anciens et actuels de divers campu...  \n",
              "19904187  Comme le château Saint-Louis, il s'agit d'un é...  \n",
              "12978711  Pour les entreprises dans le secteur privé don...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e96ce234-d41a-494d-86d4-d7abc7383ae1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17765420</th>\n",
              "      <td>Operating in the rugged Arctic always poses un...</td>\n",
              "      <td>Les conditions rudes de l’Arctique ont toujour...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7566010</th>\n",
              "      <td>Building a Knowledge Culture</td>\n",
              "      <td>Création d'une culture du savoir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13382656</th>\n",
              "      <td>More than 360 current and former Cadets of the...</td>\n",
              "      <td>Plus de 360 anciens et actuels de divers campu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19904187</th>\n",
              "      <td>Like the Château Saint-Louis it was a 2-storey...</td>\n",
              "      <td>Comme le château Saint-Louis, il s'agit d'un é...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12978711</th>\n",
              "      <td>• L'administration québécoise trailed the Queb...</td>\n",
              "      <td>Pour les entreprises dans le secteur privé don...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e96ce234-d41a-494d-86d4-d7abc7383ae1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e96ce234-d41a-494d-86d4-d7abc7383ae1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e96ce234-d41a-494d-86d4-d7abc7383ae1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a21a7ed-b9d4-428d-8034-0dd7e3da774e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a21a7ed-b9d4-428d-8034-0dd7e3da774e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a21a7ed-b9d4-428d-8034-0dd7e3da774e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the `train.csv` file alone already has many exmaples, using subset of it, create a dataset and divide to `train_dataset` and `val_dataset`. In this document, 14000 examples was sampled from the `train.csv`.\n",
        "\n",
        "You  have to create a tf.Dataset and each example has following structure:\n",
        "`((enc_input, dec_input), dec_ouput)` where\n",
        "```\n",
        "enc_input: (None, n_input)\n",
        "dec_input: (None, n_output)\n",
        "dec_output: (None, n_output)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "The output shape of decoder in transformer model is `(None, n_output, vocab_size)`, so you have to use `SparseCategoricalCorssEntropy` when calculating loss."
      ],
      "metadata": {
        "id": "b_84aajWFqKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the steps to create `train_dataset` and `val_dataset` using loaded `df`."
      ],
      "metadata": {
        "id": "JhHvSpobEfF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Add [START] and [END] tokens to all English and Fench sentences, and remove any rows if number of tokens is bigger than 64."
      ],
      "metadata": {
        "id": "afVjliKwF1y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dataset(df):\n",
        "  # remove special characters\n",
        "  for column in df.columns:\n",
        "    df[column] = df[column].apply(lambda x: re.sub(r'[\\n\\t]|[^a-zA-Z0-9\\s.]', '', str(x)))\n",
        "\n",
        "  # remove too long en\n",
        "  df = df[df['en'].apply(lambda x: len(x.split()) <= 64)]\n",
        "  # remove too long fr\n",
        "  df = df[df['fr'].apply(lambda x: len(x.split()) <= 64)]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "N1TbQDP3jLaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:, 'en'] = '[START] ' + df['en'] + ' [END]'\n",
        "df.loc[:, 'fr'] = '[START] ' + df['fr'] + ' [END]'"
      ],
      "metadata": {
        "id": "H694iqeqiU0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = clean_dataset(df)"
      ],
      "metadata": {
        "id": "ZdEnnIo_jj41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXS64PmIZANC",
        "outputId": "11a5f203-2f66-4917-c3e5-ec39fe55a18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1700562"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df.head()"
      ],
      "metadata": {
        "id": "OXSYVe1wjoDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "28a671eb-ef70-4752-b8cc-76f461bc5fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                         en  \\\n",
              "17765420  START Operating in the rugged Arctic always po...   \n",
              "7566010              START Building a Knowledge Culture END   \n",
              "13382656  START More than 360 current and former Cadets ...   \n",
              "19904187  START Like the Chteau SaintLouis it was a 2sto...   \n",
              "12978711  START  Ladministration qubcoise trailed the Qu...   \n",
              "\n",
              "                                                         fr  \n",
              "17765420  START Les conditions rudes de lArctique ont to...  \n",
              "7566010            START Cration dune culture du savoir END  \n",
              "13382656  START Plus de 360 anciens et actuels de divers...  \n",
              "19904187  START Comme le chteau SaintLouis il sagit dun ...  \n",
              "12978711  START Pour les entreprises dans le secteur pri...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-067807ad-008a-4f58-a635-36d8f3672a36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17765420</th>\n",
              "      <td>START Operating in the rugged Arctic always po...</td>\n",
              "      <td>START Les conditions rudes de lArctique ont to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7566010</th>\n",
              "      <td>START Building a Knowledge Culture END</td>\n",
              "      <td>START Cration dune culture du savoir END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13382656</th>\n",
              "      <td>START More than 360 current and former Cadets ...</td>\n",
              "      <td>START Plus de 360 anciens et actuels de divers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19904187</th>\n",
              "      <td>START Like the Chteau SaintLouis it was a 2sto...</td>\n",
              "      <td>START Comme le chteau SaintLouis il sagit dun ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12978711</th>\n",
              "      <td>START  Ladministration qubcoise trailed the Qu...</td>\n",
              "      <td>START Pour les entreprises dans le secteur pri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-067807ad-008a-4f58-a635-36d8f3672a36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-067807ad-008a-4f58-a635-36d8f3672a36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-067807ad-008a-4f58-a635-36d8f3672a36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c29a0eb3-674d-4be6-80e6-ccece0ab5b29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c29a0eb3-674d-4be6-80e6-ccece0ab5b29')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c29a0eb3-674d-4be6-80e6-ccece0ab5b29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cleaned_df"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(cleaned_df, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "0ngvXz5ROewl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete memory in df ad cleaned_df\n",
        "del df\n",
        "del cleaned_df\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "6f1snVaGGrB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb80d2b-2c52-44c8-aea6-fd432e398bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create two instances of the `Tokenizer`: one for English and another for French. Update their word vocabularies by passing all English and French sentences from train_df to the `fit_on_texts` method."
      ],
      "metadata": {
        "id": "jZIkZ1EGF-Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_tokenizer = Tokenizer(num_words=10000)\n",
        "en_tokenizer.fit_on_texts(train_df['en'])"
      ],
      "metadata": {
        "id": "vKTn7_o18GyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fr_tokenizer = Tokenizer(num_words=10000)\n",
        "fr_tokenizer.fit_on_texts(train_df['fr'])"
      ],
      "metadata": {
        "id": "aVgxWHq9S8cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(en_tokenizer.word_index))\n",
        "print(len(fr_tokenizer.word_index))"
      ],
      "metadata": {
        "id": "YztXVYsdTCFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5e8a73-5271-4703-af67-50cbb73f0dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "485848\n",
            "498672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you will notice that `len(en_tokenizer.index_word)` and `len(fr_tokenizer.word_index)` are larger than the value you set for the `num_words` parameter in the `fit_on_texts` method. This discrepancy occurs because the `num_words` limitation is applied during the `texts_to_sequences` method, not during the initial fitting.\n",
        "\n",
        "The `word_index` and `index_word` dictionaries are ordered by the frequency of each word in the corpus. When using `texts_to_sequences`, it will use words up to num_words index in the vocab."
      ],
      "metadata": {
        "id": "dxlKB9BfGBUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 64\n",
        "max_output_length = 64\n",
        "\n",
        "def encode_texts(tokenizer, texts, max_len):\n",
        "  sequences = tokenizer.texts_to_sequences(texts)\n",
        "  padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "  return padded_sequences\n",
        "\n",
        "def prepare_dataset(df):\n",
        "  input_seqs = encode_texts(en_tokenizer, df['en'], max_input_length)\n",
        "  output_seqs = encode_texts(fr_tokenizer, df['fr'], max_output_length+1)\n",
        "\n",
        "  dec_input = output_seqs[:, :-1]\n",
        "  dec_output = output_seqs[:, 1:]\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices(((input_seqs, dec_input), dec_output))"
      ],
      "metadata": {
        "id": "VRgkjZHWLySs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = prepare_dataset(train_df).shuffle(10000).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = prepare_dataset(val_df).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "7AML18hh84FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example in val_dataset.take(1):\n",
        "  inputs, output = example\n",
        "  enc_input, dec_input = inputs\n",
        "  print(enc_input.shape)\n",
        "  print(dec_input.shape)\n",
        "  print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU-i4mjb9a3Z",
        "outputId": "9da98e76-2d6d-4047-ec1d-d9d086af1a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 64)\n",
            "(32, 64)\n",
            "(32, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Transformer Model"
      ],
      "metadata": {
        "id": "3TJGpb6q_Cxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embedding Block"
      ],
      "metadata": {
        "id": "O7B_Bt54wt7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, embedding_dim):\n",
        "  \"\"\" Creates a postional encoding tensor.\n",
        "\n",
        "  Inputs:\n",
        "    length: sequence length\n",
        "    embedding_dim: d_model of a embedding layer\n",
        "\n",
        "  Outputs:\n",
        "    positional encoding tensor with shape of (length, embedding_dim)\n",
        "\n",
        "  \"\"\"\n",
        "  i = np.arange(embedding_dim/2)[np.newaxis, :] # (1, half_embedding_dim)\n",
        "  exponent = 2*i/embedding_dim\n",
        "  denominator = 1 / (10000 ** exponent)\n",
        "  positions = np.arange(length)[:, np.newaxis] # (seq, 1)\n",
        "\n",
        "  angle_rads = positions * denominator\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "Qec3kmfU_EJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  \"\"\" Custom Keras layer which encapsulates Embedding Layer and Positional Encoding.\n",
        "\n",
        "  Attributes:\n",
        "    d_model (int): embedding of the Embedding Block\n",
        "    embedding (tf.keras.layers.Embedding): Embedding layer, which takes (None, n) and outputs (None, n, d_model)\n",
        "    pos_encoding (tf.tensor): positional encoding tensor with shape of (n, d_model)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, embedding_dim=d_model) # (None, seq_length=2048, embdding_dim)\n",
        "\n",
        "  def call(self, x):\n",
        "    \"\"\" Add positional encoding to the output got by inputting x to the Embedding Layer\n",
        "\n",
        "    Inputs:\n",
        "      x: (None, n_input)\n",
        "\n",
        "    Outputs:\n",
        "      x: (None, n_input, d_model)\n",
        "    \"\"\"\n",
        "    # x: (None, seq)\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # x: (None, seq, embedding_dim)\n",
        "\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "\n",
        "    pos_encoding = self.pos_encoding[tf.newaxis, :length, :] # (None, seq_length, embedding_dim)\n",
        "    x = x + pos_encoding\n",
        "    return x"
      ],
      "metadata": {
        "id": "x0sryyFx_ef6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create MultihHeadAttention Blocks"
      ],
      "metadata": {
        "id": "OhSvybqgwxlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ],
      "metadata": {
        "id": "Q5sreg-r_gKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  \"\"\" Second MHA block in decoder. It takes K, V from Encoder and Q from previous Add&Norm Layer in Decoder\n",
        "\n",
        "  Inputs:\n",
        "    x: (None, n_target, embedding_dim). Output of Encoder is inputted as K, V.\n",
        "    context: The outptu of encoder block, has shape of (None, n_input, embedding_dim). Inputted as Q.\n",
        "\n",
        "  Outputs:\n",
        "    x: (None, n_target, embedding_dim)\n",
        "  \"\"\"\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True\n",
        "    )\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "ptTFXTZA_hli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  \"\"\" First MHA Block in Decoder. It uses LookAhed masking\n",
        "\n",
        "  Methods:\n",
        "    call\n",
        "      Inputs:\n",
        "        x: (None, n_target, embedding_dim)\n",
        "\n",
        "      Outputs:\n",
        "        x: (None, n_target, embedding_dim)\n",
        "  \"\"\"\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "eL5eQ2pC_jDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  \"\"\" MHA Block in Encoder\n",
        "\n",
        "  Inputs:\n",
        "    x: (None, n_input, d_model). This will be inputted as Q, K, V to the MHA block.\n",
        "\n",
        "  Outputs:\n",
        "    x: (None, n_input, d_model)\n",
        "  \"\"\"\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "GSkf9SWW_k9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create FeedFowardBlocks"
      ],
      "metadata": {
        "id": "nHfhOlKCtS_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  \"\"\" Two instance of it will be created, and one will be used in Encoder and other one will be used in Deocder.\n",
        "  \"\"\"\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      # (None, n, embedding_dim)\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      # (None, n, diff)\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      # (None, n, embedding_dim)\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "PySXH1MQ_mE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Encoder"
      ],
      "metadata": {
        "id": "N38wBTD-tXUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "kltDw5ue_nF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads,dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # x: (None, x_input)\n",
        "    x = self.pos_embedding(x)\n",
        "    # x: (None, x_input, embedding_im)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    # x: (None, x_input, embedding_dim)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "asxqyKzz_oiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Decoder"
      ],
      "metadata": {
        "id": "F4vX418ktZ4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "rqv_uVn6_p3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.pos_embedding(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ],
      "metadata": {
        "id": "sjDN_sDg_rEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the model"
      ],
      "metadata": {
        "id": "KkPsPsIatbxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ],
      "metadata": {
        "id": "hG1hxUwG_seJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = NUM_LAYERS\n",
        "d_model = D_MODEL\n",
        "dff = DFF\n",
        "num_heads = NUM_HEADS\n",
        "dropout_rate = DROPOUT_RATE"
      ],
      "metadata": {
        "id": "DnMjMCO-_t55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    vocab_size=10000,\n",
        "    dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "mWGOu4CY_vzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_enc_input = np.random.rand(32, 64)\n",
        "sample_dec_input = np.random.rand(32, 64)\n",
        "output = transformer((sample_enc_input, sample_dec_input))\n",
        "output.shape"
      ],
      "metadata": {
        "id": "7Af5j2uQAsY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0f463f-9be2-42a7-ed7c-8a8c943cb940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 64, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "id": "3rj3ZE0IBN66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e621f2-dbcd-41e7-e29f-b510d6e54325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_1 (\u001b[38;5;33mEncoder\u001b[0m)                  │ ?                           │       \u001b[38;5;34m7,298,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_1 (\u001b[38;5;33mDecoder\u001b[0m)                  │ ?                           │      \u001b[38;5;34m11,507,712\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │       \u001b[38;5;34m2,570,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)                  │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,298,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)                  │ ?                           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">11,507,712</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,375,760\u001b[0m (81.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,375,760</span> (81.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,375,760\u001b[0m (81.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,375,760</span> (81.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the model"
      ],
      "metadata": {
        "id": "xOKyThaVgd6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "custom learning rate scheduler"
      ],
      "metadata": {
        "id": "-ihnImckuGAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=WARMUP_STEPS):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "jFSJSBTdge-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)"
      ],
      "metadata": {
        "id": "qmxINhmgghDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "custom loss"
      ],
      "metadata": {
        "id": "EK8RycIWwKDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "  \"\"\"\n",
        "  Calculates SparceCrossEntropy Loss between label and pred, then multiply it with mask tensor.\n",
        "  Then return sum of it.\n",
        "\n",
        "  Inputs:\n",
        "    label: (None, sequence_length)\n",
        "    pred: (None,sequence_length, vocab_size)\n",
        "  \"\"\"\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "_8MV9tqBGkK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "custom accuracy"
      ],
      "metadata": {
        "id": "NNxguSCwwLpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "gTnD3YyEgjtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "Keddx_X6glvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Inferencing"
      ],
      "metadata": {
        "id": "4BZA1QsqvjSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "g8vtbBjBvsL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = transformer.fit(train_dataset, epochs=5, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PicS3QQlhNwG",
        "outputId": "ebb6af63-529b-4990-addc-11b81c20242a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m45172/45172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m863s\u001b[0m 18ms/step - loss: 5.1763 - masked_accuracy: 0.2481 - val_loss: 2.7951 - val_masked_accuracy: 0.4892\n",
            "Epoch 2/5\n",
            "\u001b[1m45172/45172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m807s\u001b[0m 18ms/step - loss: 2.6992 - masked_accuracy: 0.5038 - val_loss: 2.5375 - val_masked_accuracy: 0.5276\n",
            "Epoch 3/5\n",
            "\u001b[1m45172/45172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m784s\u001b[0m 17ms/step - loss: 2.4848 - masked_accuracy: 0.5349 - val_loss: 2.4555 - val_masked_accuracy: 0.5398\n",
            "Epoch 4/5\n",
            "\u001b[1m45172/45172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m794s\u001b[0m 18ms/step - loss: 2.3891 - masked_accuracy: 0.5492 - val_loss: 2.4116 - val_masked_accuracy: 0.5473\n",
            "Epoch 5/5\n",
            "\u001b[1m45172/45172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 18ms/step - loss: 2.3269 - masked_accuracy: 0.5584 - val_loss: 2.3813 - val_masked_accuracy: 0.5516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "6IfJfLmqvtjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_random_example():\n",
        "  \"\"\" Extract a random example from a val_df and returns English sentence and Ground Truth French sentence in a tuple.\n",
        "\n",
        "  Inputs: None\n",
        "\n",
        "  Outputs:\n",
        "    tuple of a English sentence and a original French translation\n",
        "  \"\"\"\n",
        "  random_row = random.randint(0, len(val_df) - 1)\n",
        "\n",
        "  # Extract the article and highlights\n",
        "  en = val_df.iloc[random_row]['en']\n",
        "  fr = val_df.iloc[random_row]['fr']\n",
        "\n",
        "  return (en, fr)"
      ],
      "metadata": {
        "id": "LV52Kxj-Amr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(example):\n",
        "  \"\"\" For given example, prints English sentence, ground truth French translation and predicted translation.\n",
        "\n",
        "  Inputs:\n",
        "    example: tuple of english sentence and original french translation\n",
        "\n",
        "  Outputs:\n",
        "    None\n",
        "  \"\"\"\n",
        "  en, fr = example\n",
        "  end_token_index = fr_tokenizer.word_index['end']\n",
        "\n",
        "  # encode input\n",
        "  enc_input = en_tokenizer.texts_to_sequences([en])\n",
        "  enc_input = pad_sequences(enc_input, maxlen=64, padding='post')\n",
        "\n",
        "  # decoder input\n",
        "  dec_input = fr_tokenizer.texts_to_sequences(['[START]'])\n",
        "  dec_input = pad_sequences(dec_input, maxlen=64, padding='post')\n",
        "\n",
        "  max_gen_length = 64\n",
        "\n",
        "  for i in range(max_gen_length-1):\n",
        "    pred = transformer((enc_input, dec_input), training=False)\n",
        "    pred = tf.argmax(pred, axis=-1)\n",
        "\n",
        "\n",
        "    next_token = pred[0][i]\n",
        "\n",
        "    # if model generated end token, stop the generation.\n",
        "    if next_token == end_token_index:\n",
        "      break\n",
        "\n",
        "    dec_input[0][i+1] = next_token\n",
        "\n",
        "  pred = fr_tokenizer.sequences_to_texts(dec_input)\n",
        "\n",
        "\n",
        "  print(f\"Englsih Sentence: {en}\\n\")\n",
        "  print(f\"True French Sentence: {fr}\\n\")\n",
        "  print(f\"Predicted French Sentence: {pred[0]}\")"
      ],
      "metadata": {
        "id": "IT9m9R6K-cyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = extract_random_example()\n",
        "inference(example)"
      ],
      "metadata": {
        "id": "aum1yGF5Y-r5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164d1fc8-77d1-4b38-d9a4-d4b14a4b1411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Englsih Sentence: START Departmental officials have subsequently advised that action has been taken to address this concern. END\n",
            "\n",
            "True French Sentence: START Les fonctionnaires du Ministre ont par la suite fait savoir que des mesures avaient t prises pour rgler ce problme. END\n",
            "\n",
            "Predicted French Sentence: start les responsables ministriels ont ensuite inform que des mesures ont t prises pour rgler cette question\n"
          ]
        }
      ]
    }
  ]
}